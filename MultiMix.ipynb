{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet-resnet18.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayaanzhaque/MultiMix/blob/main/MultiMix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N90-BlegJZfs"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCitpQdkJNdI"
      },
      "source": [
        "import torch\n",
        "import pdb\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"GPU not available. CPU training will be too slow.\")\n",
        "\n",
        "print(\"device name\", torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyZu5W66HsVv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7yQvcaneUVz"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import random\n",
        "import cv2\n",
        "import copy\n",
        "import os\n",
        "import pdb\n",
        "import time\n",
        "import gc\n",
        "from scipy.io import loadmat\n",
        "\n",
        "import PIL\n",
        "import PIL.ImageOps\n",
        "import PIL.ImageEnhance\n",
        "import PIL.ImageDraw\n",
        "from PIL import Image\n",
        "\n",
        "from collections import namedtuple, defaultdict\n",
        "from torch.jit.annotations import Optional\n",
        "from copy import copy\n",
        "from itertools import cycle\n",
        "\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8nZ6_mKMsJs"
      },
      "source": [
        "\n",
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c045hVMRonm"
      },
      "source": [
        "# load segmentation dataset\n",
        "datamat = loadmat('/content/drive/My Drive/Research/jsrt.mat')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lk5V3TbYQE6"
      },
      "source": [
        "datamat.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHmfdO-KT4zl"
      },
      "source": [
        "x_train = datamat[\"x_train\"]\n",
        "y_train = datamat[\"y_train\"]\n",
        "x_val = datamat[\"x_val\"]\n",
        "y_val = datamat[\"y_val\"]\n",
        "x_test = datamat[\"x_test\"]\n",
        "y_test = datamat[\"y_test\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wtq2m7TkXN5F"
      },
      "source": [
        "x_train = np.array(x_train).reshape(len(x_train),256, 256)\n",
        "y_train = y_train[:,:,:,0] + y_train[:,:,:,1]\n",
        "y_train = np.array(y_train).reshape(len(y_train),1, 256, 256)\n",
        "\n",
        "x_val = np.array(x_val).reshape(len(x_val),256, 256)\n",
        "y_val = y_val[:,:,:,0] + y_val[:,:,:,1]\n",
        "y_val = np.array(y_val).reshape(len(y_val),1, 256, 256)\n",
        "\n",
        "x_test = np.array(x_test).reshape(len(x_test),256, 256)\n",
        "y_test = y_test[:,:,:,0] + y_test[:,:,:,1]\n",
        "y_test = np.array(y_test).reshape(len(y_test),1, 256, 256)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg2FqLRGBEJT"
      },
      "source": [
        "## Prepare Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-UTr03eAROb"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "  def __init__(self, x, y, transform=None):\n",
        "    self.input_images = x\n",
        "    self.target_masks = y\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = self.input_images[idx]\n",
        "    mask = self.target_masks[idx]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return [image, mask]\n",
        "\n",
        "# use the same transformations for train/val in this example\n",
        "trans = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5), (0.5))\n",
        "])\n",
        "\n",
        "train_set = Dataset(x_train, y_train, transform = trans)\n",
        "val_set = Dataset(x_val, y_val, transform = trans)\n",
        "\n",
        "# print(len(train_set))\n",
        "\n",
        "labeled_size = 10\n",
        "unlabeled_size = len(train_set) - labeled_size\n",
        "labeled_ds, unlabeled_ds = random_split(train_set, [labeled_size, unlabeled_size])\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "dataloaders = {\n",
        "  'train': DataLoader(labeled_ds, batch_size=batch_size, shuffle=True, drop_last = True, num_workers=2),\n",
        "  'unlabeled': DataLoader(unlabeled_ds, batch_size = batch_size, shuffle = True, drop_last = True, num_workers = 2),\n",
        "  'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, drop_last = True, num_workers=2)\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNO7b5p8Pemr"
      },
      "source": [
        "# Augmentations\n",
        "PARAMETER_MAX = 10\n",
        "\n",
        "\n",
        "def AutoContrast(img, **kwarg):\n",
        "    return PIL.ImageOps.autocontrast(img)\n",
        "\n",
        "\n",
        "def Brightness(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
        "\n",
        "\n",
        "def Color(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
        "\n",
        "\n",
        "def Contrast(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
        "\n",
        "\n",
        "def Cutout(img, v, max_v, bias=0):\n",
        "    if v == 0:\n",
        "        return img\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    v = int(v * min(img.size))\n",
        "    return CutoutAbs(img, v)\n",
        "\n",
        "\n",
        "def CutoutAbs(img, v, **kwarg):\n",
        "    w, h = img.size\n",
        "    x0 = np.random.uniform(0, w)\n",
        "    y0 = np.random.uniform(0, h)\n",
        "    x0 = int(max(0, x0 - v / 2.))\n",
        "    y0 = int(max(0, y0 - v / 2.))\n",
        "    x1 = int(min(w, x0 + v))\n",
        "    y1 = int(min(h, y0 + v))\n",
        "    xy = (x0, y0, x1, y1)\n",
        "    color = (0)\n",
        "    img = img.copy()\n",
        "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
        "    return img\n",
        "\n",
        "\n",
        "def Equalize(img, **kwarg):\n",
        "    return PIL.ImageOps.equalize(img)\n",
        "\n",
        "\n",
        "def Identity(img, **kwarg):\n",
        "    return img\n",
        "\n",
        "\n",
        "def Invert(img, **kwarg):\n",
        "    return PIL.ImageOps.invert(img)\n",
        "\n",
        "\n",
        "def Posterize(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    return PIL.ImageOps.posterize(img, v)\n",
        "\n",
        "\n",
        "def Rotate(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.rotate(v)\n",
        "\n",
        "\n",
        "def Sharpness(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
        "\n",
        "\n",
        "def ShearX(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
        "\n",
        "\n",
        "def ShearY(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
        "\n",
        "\n",
        "def Solarize(img, v, max_v, bias=0):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    return PIL.ImageOps.solarize(img, 256 - v)\n",
        "\n",
        "\n",
        "def SolarizeAdd(img, v, max_v, bias=0, threshold=128):\n",
        "    v = _int_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    img_np = np.array(img).astype(np.int)\n",
        "    img_np = img_np + v\n",
        "    img_np = np.clip(img_np, 0, 255)\n",
        "    img_np = img_np.astype(np.uint8)\n",
        "    img = Image.fromarray(img_np)\n",
        "    return PIL.ImageOps.solarize(img, threshold)\n",
        "\n",
        "\n",
        "def TranslateX(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    v = int(v * img.size[0])\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
        "\n",
        "\n",
        "def TranslateY(img, v, max_v, bias=0):\n",
        "    v = _float_parameter(v, max_v) + bias\n",
        "    if random.random() < 0.5:\n",
        "        v = -v\n",
        "    v = int(v * img.size[1])\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
        "\n",
        "\n",
        "def _float_parameter(v, max_v):\n",
        "    return float(v) * max_v / PARAMETER_MAX\n",
        "\n",
        "\n",
        "def _int_parameter(v, max_v):\n",
        "    return int(v * max_v / PARAMETER_MAX)\n",
        "\n",
        "\n",
        "def augment_pool():\n",
        "    augs = [\n",
        "            (AutoContrast, None, None),\n",
        "            (Brightness, 0.9, 0.05),\n",
        "            (Contrast, 0.9, 0.05),\n",
        "            (Equalize, None, None),\n",
        "            (Identity, None, None),\n",
        "            (Posterize, 4, 4),\n",
        "            (Rotate, 30, 0),\n",
        "            (Sharpness, 0.9, 0.05),\n",
        "            (ShearX, 0.3, 0),\n",
        "            (ShearY, 0.3, 0),\n",
        "            (Solarize, 256, 0),\n",
        "            (TranslateX, 0.3, 0),\n",
        "            (TranslateY, 0.3, 0)\n",
        "            ]\n",
        "    return augs\n",
        "\n",
        "class RandAugmentMC(object):\n",
        "    def __init__(self, n, m):\n",
        "        assert n >= 1\n",
        "        assert 1 <= m <= 10\n",
        "        self.n = n\n",
        "        self.m = m\n",
        "        self.augment_pool = augment_pool()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_pool, k=self.n)\n",
        "        for op, max_v, bias in ops:\n",
        "            v = np.random.randint(1, self.m)\n",
        "            if random.random() < 0.5:\n",
        "                img = op(img, v=v, max_v=max_v, bias=bias)\n",
        "        # img = CutoutAbs(img, 128) \n",
        "        return img"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwd5je4cpSJ5"
      },
      "source": [
        "# load classification dataset\n",
        "data_dir = '/content/drive/My Drive/Colab Notebooks/chest_xray'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.Grayscale(num_output_channels=1),\n",
        "  transforms.Resize((256, 256)), \n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5), (0.5))\n",
        "])\n",
        "\n",
        "transform_weak = transforms.Compose([\n",
        "  transforms.Grayscale(num_output_channels=1),\n",
        "  transforms.Resize((256, 256)),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.RandomCrop(size=256, padding=int(256*0.125), padding_mode='reflect'),\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_strong = transforms.Compose([\n",
        "  transforms.Grayscale(num_output_channels=1),\n",
        "  transforms.Resize((256, 256)),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.RandomCrop(size=256, padding=int(32*0.125), padding_mode='reflect'),\n",
        "  RandAugmentMC(n=2, m=10),\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = ImageFolder(data_dir+'/train', \n",
        "                      transform = transform)\n",
        "\n",
        "# create subset\n",
        "labeled_size = 1000\n",
        "val_size = round(len(dataset) * 0.1)\n",
        "unlabeled_size = len(dataset) - labeled_size - val_size\n",
        "labeled_ds, val_ds, unlabeled_ds = random_split(dataset, [labeled_size, val_size, unlabeled_size])\n",
        "\n",
        "# apply augmentations\n",
        "\n",
        "labeled_ds = copy(labeled_ds)\n",
        "labeled_ds.dataset = copy(dataset)\n",
        "\n",
        "unlabeled_ds_weak = copy(unlabeled_ds)\n",
        "# unlabeled_ds_weak = copy(labeled_ds)\n",
        "unlabeled_ds_weak.dataset = copy(dataset)\n",
        "\n",
        "unlabeled_ds_strong = copy(unlabeled_ds)\n",
        "# unlabeled_ds_strong = copy(labeled_ds)\n",
        "unlabeled_ds_strong.dataset = copy(dataset)\n",
        "\n",
        "#create augmentations\n",
        "labeled_ds.dataset.transform = transform_weak\n",
        "unlabeled_ds_weak.dataset.transform = transform_weak\n",
        "unlabeled_ds_strong.dataset.transform = transform_strong\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "dataloadersClassifier = {\n",
        "  'train': DataLoader(labeled_ds, batch_size, shuffle=False, num_workers=2, drop_last = True, pin_memory=True),\n",
        "  'val': DataLoader(val_ds, batch_size, num_workers=2, drop_last = True, pin_memory=True),\n",
        "  'weak': DataLoader(unlabeled_ds_weak, batch_size, shuffle=False, num_workers=2, drop_last = True, pin_memory=True),\n",
        "  'strong': DataLoader(unlabeled_ds_strong, batch_size, shuffle=False, num_workers=2, drop_last = True, pin_memory=True)\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7XRZIKtCN8E"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6d0QadwGDl_"
      },
      "source": [
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.InstanceNorm2d(in_channels),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout(0.25)\n",
        "    )   \n",
        "\n",
        "def generate_saliency(inputs, encoder, optimizer):\n",
        "  inputs2 = copy(inputs)\n",
        "  inputs2.requires_grad = True\n",
        "  encoder.eval()\n",
        "\n",
        "  conv5, conv4, conv3, conv2, conv1, scores = encoder(inputs2)\n",
        "\n",
        "  score_max, score_max_index = torch.max(scores, 1)\n",
        "  score_max.backward(torch.FloatTensor([1.0]*score_max.shape[0]).to(device))\n",
        "  saliency, _ = torch.max(inputs2.grad.data.abs(),dim=1)\n",
        "  saliency = inputs2.grad.data.abs()\n",
        "  optimizer.zero_grad()\n",
        "  encoder.train()\n",
        "\n",
        "  return saliency\n",
        "\n",
        "class MultiMix(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class = 1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(1)\n",
        "        self.decoder = Decoder(1)\n",
        "        self.generate_saliency = generate_saliency\n",
        "        \n",
        "\n",
        "    def forward(self, x, optimizer):\n",
        "        \n",
        "        saliency = self.generate_saliency(x, self.encoder, optimizer)\n",
        "        conv5, conv4, conv3, conv2, conv1, outC = self.encoder(x)\n",
        "        outSeg = self.decoder(x, conv5, conv4, conv3, conv2, conv1, saliency)\n",
        "\n",
        "        # return outSeg, outC, saliency\n",
        "        return outSeg, outC\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class = 1):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.dconv_down1 = double_conv(1, 16)\n",
        "        self.dconv_down2 = double_conv(16, 32)\n",
        "        self.dconv_down3 = double_conv(32, 64)\n",
        "        self.dconv_down4 = double_conv(64, 128)\n",
        "        self.dconv_down5 = double_conv(128, 256)      \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))       \n",
        "        self.fc = nn.Linear(256, 2) \n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "        \n",
        "        conv3 = self.dconv_down3(x)\n",
        "        x = self.maxpool(conv3)   \n",
        "\n",
        "        conv4 = self.dconv_down4(x)\n",
        "        x = self.maxpool(conv4)\n",
        "\n",
        "        conv5 = self.dconv_down5(x)\n",
        "        x1 = self.maxpool(conv5)\n",
        "        \n",
        "        avgpool = self.avgpool(x1)\n",
        "        avgpool = avgpool.view(avgpool.size(0), -1)\n",
        "        outC = self.fc(avgpool)\n",
        "        \n",
        "        return conv5, conv4, conv3, conv2, conv1, outC\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class = 1, nonlocal_mode='concatenation', attention_dsample = (2,2)):\n",
        "        super().__init__()\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.dconv_up4 = double_conv(256 + 128 + 2, 128)\n",
        "        self.dconv_up3 = double_conv(128 + 64, 64)\n",
        "        self.dconv_up2 = double_conv(64 + 32, 32)\n",
        "        self.dconv_up1 = double_conv(32 + 16, 16)\n",
        "        self.conv_last = nn.Conv2d(16, n_class, 1)\n",
        "\n",
        "        self.conv_last_saliency = nn.Conv2d(17, n_class, 1)\n",
        "        \n",
        "        \n",
        "    def forward(self, input, conv5, conv4, conv3, conv2, conv1, saliency):\n",
        "  \n",
        "        bridge = torch.cat([input, saliency], dim = 1)\n",
        "        bridge = nn.functional.interpolate(bridge, scale_factor=0.125, mode='bilinear', align_corners=True)\n",
        "\n",
        "        x = self.upsample(conv5)        \n",
        "        x = torch.cat([x, conv4, bridge], dim=1)\n",
        "\n",
        "        x = self.dconv_up4(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv3], dim=1)       \n",
        "\n",
        "        x = self.dconv_up3(x)\n",
        "        x = self.upsample(x)        \n",
        "        # pdb.set_trace()\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "\n",
        "        x = self.dconv_up2(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv1], dim=1) \n",
        "\n",
        "        x = self.dconv_up1(x)\n",
        "        \n",
        "        out = self.conv_last(x)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ65Br1oDCOX"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY0Vk2VDCAiz"
      },
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# model = MultiMix(1)\n",
        "# model = model.to(device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaZdFgOnGA_p"
      },
      "source": [
        "#model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoVYhHpbCSdY"
      },
      "source": [
        "# import gc \n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# from torchsummary import summary\n",
        "# summary(model, input_size=(1, 256, 256))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7rAEQCUEI2v"
      },
      "source": [
        "# Define the main training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjt9JeTuDY6D"
      },
      "source": [
        "checkpoint_path = \"model.pth\"\n",
        "\n",
        "def dice_loss(pred, target, smooth = 1.):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()    \n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "    \n",
        "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
        "    \n",
        "    return loss.mean()\n",
        "\n",
        "def kl_divergence_class(outC, outStrong):\n",
        "  p = F.softmax(outC, dim = 1)\n",
        "  log_p = F.log_softmax(outC, dim = 1)\n",
        "  log_q = F.log_softmax(outStrong, dim = 1)\n",
        "  kl = p * (log_p - log_q)\n",
        "  \n",
        "  return kl.mean()\n",
        "\n",
        "def kl_divergence_seg(outSeg, outSegUnlabeled):\n",
        "  p = F.softmax(outSeg, dim = 1)\n",
        "  log_p = F.log_softmax(outSeg, dim = 1)\n",
        "  log_q = F.log_softmax(outSegUnlabeled, dim = 1)\n",
        "  kl = p * (log_p - log_q)\n",
        "  \n",
        "  return kl.mean()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def calc_loss(outSeg, target, outSegUnlabeled, outC, labels, outWeak, outStrong, metrics, ssl_weight = 0.25, threshold = 0.7, kl_weight = 0.01, dice_weight = 5):\n",
        "\n",
        "    predSeg = torch.sigmoid(outSeg)\n",
        "\n",
        "    dice = dice_loss(predSeg, target)\n",
        "\n",
        "    lossClassifier = criterion(outC, labels)\n",
        "\n",
        "    probsWeak = torch.softmax(outWeak, dim=1)\n",
        "    max_probs, psuedoLabels = torch.max(probsWeak, dim=1)\n",
        "    mask = max_probs.ge(threshold).float()\n",
        "\n",
        "    lossUnLabeled = (F.cross_entropy(outStrong, psuedoLabels,\n",
        "                              reduction='none') * mask).mean()\n",
        "\n",
        "    kl_class = kl_divergence_class(outC, outStrong)\n",
        "    kl_seg = kl_divergence_seg(outSeg, outSegUnlabeled)\n",
        "\n",
        "    # do KL only with segmentation for now\n",
        "    loss = lossClassifier + dice * dice_weight + (lossUnLabeled * ssl_weight) + (kl_seg * kl_weight)\n",
        "\n",
        "    metrics['lossClassifier'] += lossClassifier.data.cpu().numpy() * target.size(0)\n",
        "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
        "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def print_metrics(metrics, epoch_samples, phase):\n",
        "    outputs = []\n",
        "    for k in metrics.keys():\n",
        "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "\n",
        "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
        "\n",
        "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
        "    best_loss = 1e10\n",
        "\n",
        "    accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                # gc.collect()\n",
        "                # torch.cuda.empty_cache()\n",
        "\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "            total_train = 0\n",
        "            correct_train = 0\n",
        "            trainloader = zip(cycle(dataloaders[phase]), cycle(dataloaders[\"unlabeled\"]), cycle(dataloadersClassifier[phase]), dataloadersClassifier[\"weak\"], dataloadersClassifier[\"strong\"]) # added cycling\n",
        "            for i, (dataSeg, dataSegUnlabeled, data, dataWeak, dataStrong) in enumerate(trainloader):\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                inputs, masks = dataSeg\n",
        "                inputs, masks = inputs.to(device=device, dtype=torch.float), masks.to(device=device, dtype=torch.float)\n",
        "\n",
        "                inputsUnlabeled, masksUnlabeled = dataSegUnlabeled\n",
        "                inputsUnlabeled, masksUnlabeled = inputsUnlabeled.to(device=device, dtype=torch.float), masksUnlabeled.to(device=device, dtype=torch.float)\n",
        "\n",
        "                inputsClass, labels = data\n",
        "                inputsClass, labels = inputsClass.to(device), labels.to(device)\n",
        "\n",
        "                inputsWeak, weakLabelUnused = dataWeak\n",
        "                inputsWeak, weakLabelUnused = inputsWeak.to(device), weakLabelUnused.to(device)\n",
        "\n",
        "                inputsStrong, strongLabelUnused = dataStrong\n",
        "                inputsStrong, strongLabelUnused = inputsStrong.to(device), strongLabelUnused.to(device)\n",
        "                \n",
        "                inputsAll = torch.cat((inputs, inputsUnlabeled, inputsClass, inputsWeak, inputsStrong))\n",
        "                batch_size_seg = inputs.shape[0]\n",
        "                batch_size_seg_unlabeled = inputsUnlabeled.shape[0] + batch_size_seg\n",
        "                batch_size_class = inputsClass.shape[0] + batch_size_seg_unlabeled\n",
        "                batch_size_weak = inputsWeak.shape[0] + batch_size_class\n",
        "                batch_size_strong = inputsStrong.shape[0] + batch_size_weak\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                with torch.set_grad_enabled(True):\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "\n",
        "                        outSegAll, outClassAll = model(inputsAll, optimizer)\n",
        "\n",
        "                        outSeg = outSegAll[:batch_size_seg]\n",
        "                        outSegUnlabeled = outSegAll[batch_size_seg:batch_size_seg_unlabeled]\n",
        "                        outC = outClassAll[batch_size_seg_unlabeled:batch_size_class]\n",
        "                        outWeak = outClassAll[batch_size_class:batch_size_weak]\n",
        "                        outStrong = outClassAll[batch_size_weak:batch_size_strong]\n",
        "\n",
        "                        loss = calc_loss(outSeg, masks, outSegUnlabeled, outC, labels, outWeak, outStrong, metrics)\n",
        "\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        if (i % 10 == 0):\n",
        "                          print(\"done with batch \" + str(i))\n",
        "                    \n",
        "                        model.eval()\n",
        "                        # accuracy\n",
        "                        _, predicted = torch.max(outC, 1)\n",
        "                        total_train += labels.size(0)\n",
        "                        correct_train += predicted.eq(labels.data).sum().item()\n",
        "                        train_accuracy = 100 * correct_train / total_train\n",
        "                        model.train()\n",
        "\n",
        "                        if(i % 10 == 0):\n",
        "                          print(train_accuracy)\n",
        "\n",
        "                # statistics\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "            print_metrics(metrics, epoch_samples, phase)\n",
        "            epoch_loss = metrics['loss'] / epoch_samples\n",
        "\n",
        "            if phase == 'train':\n",
        "              scheduler.step()\n",
        "              for param_group in optimizer.param_groups:\n",
        "                  print(\"LR\", param_group['lr'])\n",
        "\n",
        "            # save the model weights\n",
        "            if phase == 'val':\n",
        "                if epoch_loss < best_loss:\n",
        "                  print(f\"saving best model to {checkpoint_path}\")\n",
        "                  best_loss = epoch_loss\n",
        "                  torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "        \n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adcdAu9ZEOLG"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfxgL303EMiy"
      },
      "source": [
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# uncomment the following code for training\n",
        "'''\n",
        "epochs = 100 \n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultiMix(1).to(device)\n",
        "  \n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=8, gamma=0.1)\n",
        "\n",
        "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs = epochs)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Iqd-GkCBhd"
      },
      "source": [
        "# Testing\n",
        "To test the code, load the provided pth file after instantiating the model. Then, run the test code and receive a prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8uM3ZBOCBBh"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultiMix(1).to(device)\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "checkpoint_path = '/content/multimix_trained_model.pth'\n",
        "model.load_state_dict(torch.load(checkpoint_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6n0T-Y4Crmy"
      },
      "source": [
        "# add the provided classification image to a folder and load it \n",
        "\n",
        "data_dir = '/content/drive/My Drive/Colab Notebooks/chest_xray'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.Grayscale(num_output_channels=1),\n",
        "  transforms.Resize((256, 256)), \n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "print(len(os.listdir(data_dir + \"/test/PNEUMONIA\")) + len(os.listdir(data_dir + \"/test/NORMAL\")))\n",
        "\n",
        "dataset = ImageFolder(data_dir+'/test', \n",
        "                      transform = transform)\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "test_loader_class = DataLoader(dataset, batch_size, num_workers=2, pin_memory=True, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rdBNKDVC0cJ"
      },
      "source": [
        "# for classification predictions, run this cell\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "predictions = np.array([])\n",
        "with torch.set_grad_enabled(True):\n",
        "  print(\"starting validation\")\n",
        "  for i, data in enumerate(test_loader_class):\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      _, outC = model(inputs, optimizer_ft)\n",
        "      _, predicted = torch.max(outC.data, 1)\n",
        "      predictions = np.append(predictions, predicted.data.cpu().numpy())\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = (correct / total) * 100 \n",
        "\n",
        "print('Accuracy of the network: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y43Ys4YPDCuQ"
      },
      "source": [
        "# to get a segmentation prediction, load the image and run the following code\n",
        "model.eval() \n",
        "\n",
        "test_dataset = Dataset(x_test, y_test, transform = trans)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "pred_masks = []\n",
        "for inputs, labels in test_loader:\n",
        "  count += 1\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  inputs = inputs.to(device=device, dtype=torch.float)\n",
        "  labels = labels.to(device=device, dtype=torch.float)\n",
        "  pred, _, = model(inputs, optimizer_ft)\n",
        "  pred = torch.sigmoid(pred)\n",
        "  pred = pred.data.cpu().numpy()\n",
        "  for i in range (len(pred)):\n",
        "    pred_masks.append(pred[i])\n",
        "\n",
        "pred_masks = np.reshape(pred_masks, [-1, 256, 256, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orxC6mq4DRxD"
      },
      "source": [
        "# to view the predicted mask, run the following\n",
        "plt.imshow(np.squeeze(pred_masks[0]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}